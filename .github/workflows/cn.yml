name: Update and Merge Phone Data

on:
  push:
    branches:
      - main
  workflow_dispatch:
  schedule:
     - cron: '0 12 1 * *' # 每月1号中午12点自动运行

permissions:
  contents: write

jobs:
  process-and-merge:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pypinyin pandas

      # ---------------------------------------------------------
      # 第一部分：数据处理流程
      # (下载SQL -> CSV -> 预处理 -> 优化生成手机号Dart)
      # 这些步骤会在 Runner 本地生成 lib/cn/ 下的中间文件，但我们最后不会提交它们
      # ---------------------------------------------------------
      
      - name: Download SQL and Convert to CSV
        run: |
          cat > convert_sql_to_csv.py << 'EOF'
          import requests
          import pandas as pd
          import csv
          import os

          def download_sql():
              url = "https://github.com/dannyhu926/phone_location/raw/refs/heads/master/mysql/phone_location.sql"
              response = requests.get(url)
              response.raise_for_status()
              return response.text

          def convert_to_csv(sql_content, csv_filepath):
              insert_statements = [line for line in sql_content.splitlines() if line.startswith("INSERT INTO `phone_location`")]
              data = []
              for statement in insert_statements:
                  values_str = statement[statement.find("VALUES") + len("VALUES"):].strip()
                  values = []
                  in_quote = False
                  current_value = ""
                  for char in values_str:
                      if char == "'":
                          in_quote = not in_quote
                      elif char == "," and not in_quote:
                          values.append(current_value.strip("'"))
                          current_value = ""
                      elif in_quote:
                          current_value += char
                  values.append(current_value.strip("'"))
                  data.append(values[1:5])

              df = pd.DataFrame(data, columns=['pref', 'phone', 'province', 'city'])
              df.to_csv(csv_filepath, index=False, quoting=csv.QUOTE_NONNUMERIC)

          if __name__ == "__main__":
              sql_content = download_sql()
              os.makedirs('lib/cn', exist_ok=True)
              convert_to_csv(sql_content, 'lib/cn/phone_location.csv')
          EOF
          python convert_sql_to_csv.py

      - name: Preprocess CSV
        run: |
          cat > preprocess_csv.py << 'EOF'
          import pandas as pd
          import csv

          df = pd.read_csv('lib/cn/phone_location.csv')
          df = df.drop(columns=['pref'])
          df['phone'] = '86' + df['phone'].astype(str).str.replace("'", "")
          df['province'] = df['province'].str.replace("'", "")
          df['city'] = df['city'].str.replace("'", "")
          df.to_csv('lib/cn/phone_location_processed.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)
          EOF
          python preprocess_csv.py

      - name: Optimize Phone Ranges and Generate Mobile Dart
        run: |
          cat > optimize_ranges.py << 'EOF'
          import pandas as pd
          from collections import defaultdict
          from pypinyin import lazy_pinyin, Style
          import os

          def convert_to_pinyin(province, city):
              p = ''.join(lazy_pinyin(province, style=Style.NORMAL))
              c = ''.join(lazy_pinyin(city, style=Style.NORMAL))
              return f"{c.title()}, {p.title()}"

          def process_csv(input_file):
              df = pd.read_csv(input_file)
              processed = set()
              result = []

              location_groups = defaultdict(list)
              for _, row in df.iterrows():
                  phone = str(row['phone'])
                  location_groups[f"{row['province']}{row['city']}"].append({
                      'phone': phone,
                      'province': row['province'],
                      'city': row['city']
                  })

              for location, numbers in location_groups.items():
                  prefix_groups = defaultdict(list)
                  for num in numbers:
                      if num['phone'] not in processed:
                          prefix = num['phone'][:-1]
                          prefix_groups[prefix].append(num)

                  for prefix, group in prefix_groups.items():
                      if len(group) == 10:
                          sorted_group = sorted(group, key=lambda x: x['phone'])
                          if all(int(n['phone'][-1]) == i for i, n in enumerate(sorted_group)):
                              first = sorted_group[0]
                              if all(n['province'] == first['province'] and n['city'] == first['city'] for n in sorted_group):
                                  result.append({
                                      'phone': int(prefix),
                                      'province': first['province'],
                                      'city': first['city']
                                  })
                                  processed.update(n['phone'] for n in sorted_group)

              for _, row in df.iterrows():
                  phone = str(row['phone'])
                  if phone not in processed:
                      result.append({
                          'phone': int(phone),
                          'province': row['province'],
                          'city': row['city']
                      })
              return result

          def optimize_phone_ranges(input_file):
              first_round = process_csv(input_file)
              temp_df = pd.DataFrame(first_round)
              temp_csv = 'lib/cn/temp_processed.csv'
              temp_df.to_csv(temp_csv, index=False)
              second_round = process_csv(temp_csv)
              
              final_df = pd.DataFrame(second_round)
              final_df.sort_values(by='phone', inplace=True)
              
              optimized_zh = {}
              optimized_en = {}

              for _, row in final_df.iterrows():
                  phone = row['phone']
                  optimized_zh[phone] = f"{row['province']}{row['city']}"
                  optimized_en[phone] = convert_to_pinyin(row['province'], row['city'])
              return optimized_zh, optimized_en

          def generate_optimized_dart_files(optimized_zh, optimized_en):
              os.makedirs('lib/cn', exist_ok=True)
              with open('lib/cn/phone_location_zh_optimized.dart', 'w', encoding='utf-8') as f:
                  f.write('// Generated by GitHub Actions - Optimized Version\n')
                  f.write('Map<int, String> get86_zh_optimized() {\n  return {\n')
                  for phone, location in optimized_zh.items():
                      f.write(f'    {phone}: "{location}",\n')
                  f.write('  };\n}\n')

              with open('lib/cn/phone_location_en_optimized.dart', 'w', encoding='utf-8') as f:
                  f.write('// Generated by GitHub Actions - Optimized Version\n')
                  f.write('Map<int, String> get86_en_optimized() {\n  return {\n')
                  for phone, location in optimized_en.items():
                      f.write(f'    {phone}: "{location}",\n')
                  f.write('  };\n}\n')

          if __name__ == "__main__":
              optimized_zh, optimized_en = optimize_phone_ranges('lib/cn/phone_location_processed.csv')
              generate_optimized_dart_files(optimized_zh, optimized_en)
          EOF
          python optimize_ranges.py

      # ---------------------------------------------------------
      # 第二部分：合并数据
      # 将仓库自带的固话数据 (lib/merged/) 和刚生成的手机数据 (lib/cn/) 
      # 合并写入到 lib/generated/metadata/geocoding/
      # ---------------------------------------------------------

      - name: Create final directory
        run: mkdir -p lib/generated/metadata/geocoding

      - name: Merge Data (Fixed + Mobile)
        run: |
          python << EOF
          import os

          def extract_map_content(file_path):
              if not os.path.exists(file_path):
                  print(f"Warning: File not found: {file_path}")
                  return ""
              
              with open(file_path, 'r', encoding='utf-8') as f:
                  content = f.read()

              # Find the start of the map data after "return {"
              start_marker = "return {"
              start_index = content.find(start_marker)
              if start_index == -1: 
                  return ""
              
              start_index += len(start_marker)
              
              # Find the matching closing brace for the map
              brace_count = 1
              end_index = start_index
              while brace_count > 0 and end_index < len(content):
                  if content[end_index] == '{':
                      brace_count += 1
                  elif content[end_index] == '}':
                      brace_count -= 1
                  end_index += 1

              return content[start_index:end_index-1].strip()

          # 固定电话数据 (仓库已有)
          fixed_line_en_path = "lib/merged/fixed_line_en.dart" 
          fixed_line_zh_path = "lib/merged/fixed_line_zh.dart"
          
          # 手机数据 (脚本生成，不提交)
          mobile_en_path = "lib/cn/phone_location_en_optimized.dart"
          mobile_zh_path = "lib/cn/phone_location_zh_optimized.dart"
          
          # 输出目录 (最终提交)
          output_dir = "lib/generated/metadata/geocoding"

          # 1. 处理英文数据
          fixed_en = extract_map_content(fixed_line_en_path)
          mobile_en = extract_map_content(mobile_en_path)
          
          with open(f"{output_dir}/86_en.dart", "w", encoding="utf-8") as f:
              f.write("// Generated and Merged by GitHub Actions\n")
              f.write("Map<int, String> get86_en() {{\n  return {{\n    // Fixed Line\n    {0},\n    // Mobile\n    {1}\n  }};\n}}".format(fixed_en, mobile_en))

          # 2. 处理中文数据
          fixed_zh = extract_map_content(fixed_line_zh_path)
          mobile_zh = extract_map_content(mobile_zh_path)

          with open(f"{output_dir}/86_zh.dart", "w", encoding="utf-8") as f:
              f.write("// Generated and Merged by GitHub Actions\n")
              f.write("Map<int, String> get86_zh() {{\n  return {{\n    // Fixed Line\n    {0},\n    // Mobile\n    {1}\n  }};\n}}".format(fixed_zh, mobile_zh))
          
          print(f"Merge completed. Output saved to {output_dir}")
          EOF

      # ---------------------------------------------------------
      # 第三部分：提交最终结果
      # 只提交 lib/generated/metadata/geocoding/ 下的文件
      # 忽略 lib/cn/ 下的 CSV 和中间 Dart 文件
      # ---------------------------------------------------------

      - name: Commit and Push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): Update geocoding data"
          file_pattern: "lib/generated/metadata/geocoding/86_*.dart"
