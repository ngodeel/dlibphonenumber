name: 自动优化并合并固话 (运行在 dlib)

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: write

jobs:
  optimize-and-merge:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout current repo
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests pandas pypinyin

      # =========================================================
      # 核心脚本：严格复刻 Stage 4 逻辑 (2轮优化) + 修复格式
      # =========================================================
      - name: Process Data
        run: |
          cat > run_process.py << 'EOF'
          import requests
          import pandas as pd
          import os
          import re
          from collections import defaultdict
          from pypinyin import lazy_pinyin, Style

          # === 1. 配置 ===
          SQL_URL = "https://github.com/dannyhu926/phone_location/raw/refs/heads/master/mysql/phone_location.sql"
          FIXED_ZH_URL = "https://raw.githubusercontent.com/haygcao/vccard/dartnumber/lib/merged/fixed_line_zh.dart"
          FIXED_EN_URL = "https://raw.githubusercontent.com/haygcao/vccard/dartnumber/lib/merged/fixed_line_en.dart"

          OUTPUT_ZH = "lib/generated/metadata/geocoding/86_zh.dart"
          OUTPUT_EN = "lib/generated/metadata/geocoding/86_en.dart"

          # === 2. 辅助函数 ===
          def convert_to_pinyin(province, city):
              p = ''.join(lazy_pinyin(province if province else "", style=Style.NORMAL))
              c = ''.join(lazy_pinyin(city if city else "", style=Style.NORMAL))
              if not city: return p.title()
              return f"{c.title()}, {p.title()}"

          def fetch_remote_lines(url):
              """下载并提取Map内容，去除原有的末尾逗号以便统一格式化"""
              print(f"Fetching {url}...")
              try:
                  resp = requests.get(url)
                  resp.raise_for_status()
                  # 提取 return { ... }; 之间的内容
                  match = re.search(r'return\s*\{([\s\S]*?)\};', resp.text)
                  lines = []
                  if match:
                      for line in match.group(1).split('\n'):
                          clean = line.strip()
                          if clean:
                              if clean.endswith(','): clean = clean[:-1]
                              lines.append(clean)
                  return lines
              except Exception as e:
                  print(f"Error fetching {url}: {e}")
                  return []

          # === 3. 核心算法 (完全照搬你的 Stage 4 process_csv) ===
          def process_csv_logic(df):
              processed = set()
              result = []
              
              # 逻辑 A: 按归属地 (Province+City) 分组
              location_groups = defaultdict(list)
              for _, row in df.iterrows():
                  phone = str(row['phone'])
                  key = f"{row['province']}{row['city']}"
                  location_groups[key].append({
                      'phone': phone,
                      'province': row['province'],
                      'city': row['city']
                  })

              # 逻辑 B: 组内按前缀分组，查找连续的 0-9
              for location, numbers in location_groups.items():
                  prefix_groups = defaultdict(list)
                  for num in numbers:
                      if num['phone'] not in processed:
                          prefix = num['phone'][:-1] # 取父级前缀
                          prefix_groups[prefix].append(num)

                  for prefix, group in prefix_groups.items():
                      # 必须刚好 10 个
                      if len(group) == 10:
                          # 排序并检查是否 0-9 连续
                          sorted_group = sorted(group, key=lambda x: x['phone'])
                          if all(int(n['phone'][-1]) == i for i, n in enumerate(sorted_group)):
                              first = sorted_group[0]
                              # 再次校验归属地一致性 (双重保险)
                              if all(n['province'] == first['province'] and n['city'] == first['city'] for n in sorted_group):
                                  result.append({
                                      'phone': int(prefix), # 合并为短号
                                      'province': first['province'],
                                      'city': first['city']
                                  })
                                  # 标记已处理
                                  processed.update(n['phone'] for n in sorted_group)

              # 逻辑 C: 添加未被合并的剩余号码
              for _, row in df.iterrows():
                  phone = str(row['phone'])
                  if phone not in processed:
                      result.append({
                          'phone': int(phone),
                          'province': row['province'],
                          'city': row['city']
                      })
              return result

          def main():
              # --- Step 1: 解析 SQL (对应你的 convert_sql_to_csv) ---
              print("1. Parsing SQL...")
              response = requests.get(SQL_URL)
              response.raise_for_status()
              
              insert_statements = [line for line in response.text.splitlines() if line.startswith("INSERT INTO `phone_location`")]
              raw_data = []
              for statement in insert_statements:
                  values_part = statement[statement.find("VALUES") + 6:].strip().strip(";")
                  rows = values_part.split("),(")
                  for row in rows:
                      row = row.replace("(", "").replace(")", "")
                      parts = [p.strip().strip("'") for p in row.split(",")]
                      if len(parts) >= 4:
                          # 对应你的 preprocess_csv: 加上 86 前缀
                          raw_data.append({
                              'phone': '86' + parts[1], 
                              'province': parts[2], 
                              'city': parts[3]
                          })
              
              current_df = pd.DataFrame(raw_data)
              print(f"   Initial count: {len(current_df)}")

              # --- Step 2: 执行两轮优化 (完全对应你的 optimize_phone_ranges) ---
              
              # Round 1 (9位 -> 8位)
              print("2. Running Optimization Round 1...")
              round1_list = process_csv_logic(current_df)
              round1_df = pd.DataFrame(round1_list)
              print(f"   Round 1 reduced to: {len(round1_df)}")

              # Round 2 (8位 -> 7位)
              print("3. Running Optimization Round 2...")
              round2_list = process_csv_logic(round1_df)
              
              # 排序
              final_df = pd.DataFrame(round2_list)
              final_df.sort_values(by='phone', inplace=True)
              print(f"   Final optimized count: {len(final_df)}")

              # --- Step 3: 生成字典 (对应你的 optimized_zh = {} 逻辑，确保无重复Key) ---
              optimized_zh = {}
              optimized_en = {}
              for _, row in final_df.iterrows():
                  phone = row['phone']
                  # 这里绝对只存地名，不存手机号
                  optimized_zh[phone] = f"{row['province']}{row['city']}"
                  optimized_en[phone] = convert_to_pinyin(row['province'], row['city'])

              # --- Step 4: 获取固话 ---
              print("4. Fetching Fixed Line Data...")
              fixed_zh_lines = fetch_remote_lines(FIXED_ZH_URL)
              fixed_en_lines = fetch_remote_lines(FIXED_EN_URL)

              # --- Step 5: 写入文件 (修正格式 Key: "Value",) ---
              print("5. Writing Final Files...")
              os.makedirs(os.path.dirname(OUTPUT_ZH), exist_ok=True)

              # === 写入中文版 ===
              with open(OUTPUT_ZH, 'w', encoding='utf-8') as f:
                  f.write('// Generated by GitHub Actions\n')
                  f.write('Map<int, String> get86_zh() {\n  return {\n')
                  
                  # 写入固话
                  for line in fixed_zh_lines:
                      f.write(f"    {line},\n")
                  
                  # 写入手机 (遍历字典，确保 Key 唯一，格式正确)
                  for phone, location in optimized_zh.items():
                      f.write(f'    {phone}: "{location}",\n')
                      
                  f.write('  };\n}\n')

              # === 写入英文版 ===
              with open(OUTPUT_EN, 'w', encoding='utf-8') as f:
                  f.write('// Generated by GitHub Actions\n')
                  f.write('Map<int, String> get86_en() {\n  return {\n')
                  
                  # 写入固话
                  for line in fixed_en_lines:
                      f.write(f"    {line},\n")
                  
                  # 写入手机
                  for phone, location in optimized_en.items():
                      f.write(f'    {phone}: "{location}",\n')
                      
                  f.write('  };\n}\n')
                  
              print("Done.")

          if __name__ == "__main__":
              main()
          EOF
          
          python run_process.py

      - name: Commit and Force Push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): Auto optimize and merge fixed line data"
          file_pattern: "lib/generated/metadata/geocoding/86_*.dart"
          branch: main
          repository: .
          push_options: '--force'
          token: ${{ secrets.YOUR_GITHUB_TOKEN }} # 加上了 Token
